Object Detection Benchmark
==========================

Based on Mqbench and `EOD <https://github.com/ModelTC/EOD>`_ , we provide an object detection benchmark on COCO dataset.
We test the two most popular object detection methods, retinanet and yolox on several Backends.

+----------+---------------+----------------+----------------+----------------+------+------+-------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+
| Backend  | w_calibration | a_calibration  | w_fakequantize | a_fakequantize | wbit | abit | `retinanet <https://github.com/ModelTC/EOD/blob/main/configs/det/retinanet/retinanet-r18-improve.yaml>`_    |     `yolox <https://github.com/ModelTC/EOD/blob/main/configs/det/retinanet/yolox_s_ret_a1_comloc.yaml>`_   |
+          +               +                +                +                +      +      +-------------------------+----------------------+------------------------------------------------------------+-------------------------+-------------------+--------------------------------------------------------------+
|          |               |                |                |                |      |      | pretrained@float32      | calibration@int8     |  qat@int8                                                  | pretrained@float32      | calibration@int8  |  qat@int8                                                    |
+==========+===============+================+================+================+======+======+=========================+======================+============================================================+=========================+===================+==============================================================+
| tensorrt | MinMax        | EMAMinMax      | Fixed          | Fixed          | 8    | 8    | 40.7                    | 40.5                 | 40.7                                                       | 40.5                    | 39.4              | 39.8                                                         |
+----------+---------------+----------------+----------------+----------------+------+------+-------------------------+----------------------+------------------------------------------------------------+-------------------------+-------------------+--------------------------------------------------------------+
| snpe     | MinMax        | EMAMinMax      | Fixed          | Fixed          | 8    | 8    | 40.7                    | 39.7                 | 40.2                                                       | 40.5                    | 38.1              | 39.8                                                         |
+----------+---------------+----------------+----------------+----------------+------+------+-------------------------+----------------------+------------------------------------------------------------+-------------------------+-------------------+--------------------------------------------------------------+
| vitis    | MinMaxFloor   | ModeMinMaxFloor| Tqt            | Tqt            | 8    | 8    | 40.7                    | 39.0                 | 40.1                                                       | 29.3*                   | 25.3              | 27.4                                                         |
+----------+---------------+----------------+----------------+----------------+------+------+-------------------------+----------------------+------------------------------------------------------------+-------------------------+-------------------+--------------------------------------------------------------+

Note*: We provide an simplified model of yolox to meet vitis operator support, which is winner solution for the Low Power Computer Vision Challenge 2021 (`LPCV2021 <https://github.com/ModelTC/LPCV2021_Winner_Solution>`_). The model is `yolox-lpcv <https://github.com/ModelTC/EOD/blob/main/configs/det/yolox/yolox_fpga.yaml>`_.


